{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7cim139-YhQ",
        "outputId": "ccddf193-3513-4543-e8a4-e8ca756cb0e1"
      },
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "K = len(np.unique(y_train)) # Classes\n",
        "Ntr = x_train.shape[0]\n",
        "Nte = x_test.shape[0]\n",
        "Din = 3072 # CIFAR10 32x32x3\n",
        "\n",
        "# Normalize pixel values\n",
        "\n",
        "mean_image = np.mean(x_train, axis=0)\n",
        "x_train = x_train - mean_image\n",
        "x_test = x_test - mean_image\n",
        "\n",
        "y_train =  tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
        "\n",
        "x_train = np.reshape(x_train,(Ntr,Din))\n",
        "x_test = np.reshape(x_test,(Nte,Din))\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "H = 200\n",
        "std=1e-5\n",
        "w1 = std*np.random.randn(Din, H)\n",
        "w2 = std*np.random.randn(H, K)\n",
        "b1 = np.zeros(H)\n",
        "b2 = np.zeros(K)\n",
        "print(\"w1:\", w1.shape)\n",
        "print(\"b1:\", b1.shape)\n",
        "print(\"w2:\", w2.shape)\n",
        "print(\"b2:\", b2.shape)\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "iterations = 300\n",
        "lr = 1.4e-2\n",
        "lr_decay= 0.999\n",
        "reg = 5e-6\n",
        "\n",
        "testing_loss_history = []\n",
        "training_loss_history = []\n",
        "testing_acc_history = []\n",
        "training_acc_history = []\n",
        "seed = 0\n",
        "rng = np.random.default_rng(seed=seed)\n",
        "\n",
        "indices = np.arange(0, Ntr, batch_size)\n",
        "\n",
        "for t in range(iterations):\n",
        "    rng.shuffle(indices)#Shuffling the dataset\n",
        "    turn = 0\n",
        "    for index in indices:\n",
        "      x=x_train[index:index+batch_size]\n",
        "      y=y_train[index:index+batch_size]\n",
        "\n",
        "      # Forward pass\n",
        "      h =1.0/(1.0 + np.exp(-(x.dot(w1)+b1)))\n",
        "      y_pred = h.dot(w2) + b2\n",
        "      h_test = 1.0/(1.0 + np.exp(-(x_test.dot(w1)+b1)))\n",
        "      y_test_pred = h_test.dot(w2)+b2\n",
        "\n",
        "      testing_loss=1./Nte*(np.square(y_test_pred-y_test)).sum() + reg * np.sum(w1*w1)\n",
        "      training_loss=1./batch_size*(np.square(y_pred-y)).sum() + reg * np.sum(w1*w1)\n",
        "      testing_loss_history.append(testing_loss)\n",
        "      training_loss_history.append(training_loss)\n",
        "\n",
        "      training_acc = 1.0 - (1/(batch_size*K))*(np.abs(np.argmax(y,axis=1) - np.argmax(y_pred,axis=1))).sum()\n",
        "      training_acc_history.append(training_acc)\n",
        "      testing_acc = 1.0 - (1/(Nte*K))*(np.abs(np.argmax(y_test,axis=1) - np.argmax(y_test_pred,axis=1))).sum()\n",
        "      testing_acc_history.append(testing_acc)\n",
        "\n",
        "      if t%10==0 and turn%20 == 0:\n",
        "          print('epoch = ', t, ' train loss = ', training_loss ,' test loss =  ', testing_loss, ' train accuracy = ', training_loss, 'test accuracy = ', testing_acc)\n",
        "\n",
        "      # Backward pass\n",
        "\n",
        "      dy_pred = 1./batch_size*2.0*(y_pred-y)#partial differentiation\n",
        "      dw2 = h.T.dot(dy_pred) + reg * w2\n",
        "      db2 = dy_pred.sum(axis=0)\n",
        "      dh = dy_pred.dot(w2.T)\n",
        "      dw1 = x.T.dot(dh*h*(1-h))+reg*w1\n",
        "      db1 = (dh*h*(1-h)).sum(axis=0) \n",
        "\n",
        "      w1 -= lr*dw1\n",
        "      w2 -= lr*dw2\n",
        "      b1 -= lr*db1\n",
        "      b2 -= lr*db2\n",
        "      lr *= lr_decay\n",
        "      turn += 1\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w1: (3072, 200)\n",
            "b1: (200,)\n",
            "w2: (200, 10)\n",
            "b2: (10,)\n",
            "epoch =  0  train loss =  1.0000093011540365  test loss =   1.0000130859835472  train accuracy =  1.0000093011540365 test accuracy =  0.6299999999999999\n",
            "epoch =  0  train loss =  0.8522196320565275  test loss =   0.8526788010036536  train accuracy =  0.8522196320565275 test accuracy =  0.7196899999999999\n",
            "epoch =  0  train loss =  0.8386110504178667  test loss =   0.8350189465520153  train accuracy =  0.8386110504178667 test accuracy =  0.71801\n",
            "epoch =  0  train loss =  0.8128039713890423  test loss =   0.810300147287014  train accuracy =  0.8128039713890423 test accuracy =  0.7539\n",
            "epoch =  0  train loss =  0.7907225131837421  test loss =   0.8007933354297438  train accuracy =  0.7907225131837421 test accuracy =  0.75937\n",
            "epoch =  10  train loss =  0.6864584527813056  test loss =   0.7416067251924591  train accuracy =  0.6864584527813056 test accuracy =  0.7975\n",
            "epoch =  10  train loss =  0.6935060429522429  test loss =   0.7370992342729467  train accuracy =  0.6935060429522429 test accuracy =  0.8001199999999999\n",
            "epoch =  10  train loss =  0.6783466709498841  test loss =   0.7385057812458229  train accuracy =  0.6783466709498841 test accuracy =  0.79858\n",
            "epoch =  10  train loss =  0.6882128314576413  test loss =   0.7384345685272248  train accuracy =  0.6882128314576413 test accuracy =  0.79634\n",
            "epoch =  10  train loss =  0.6810076964323466  test loss =   0.7418395431185717  train accuracy =  0.6810076964323466 test accuracy =  0.7970999999999999\n",
            "epoch =  20  train loss =  0.6195928015136056  test loss =   0.7335645102156058  train accuracy =  0.6195928015136056 test accuracy =  0.80229\n",
            "epoch =  20  train loss =  0.6357579001787379  test loss =   0.7340926454785093  train accuracy =  0.6357579001787379 test accuracy =  0.8021199999999999\n",
            "epoch =  20  train loss =  0.6200724973541762  test loss =   0.7339662955285687  train accuracy =  0.6200724973541762 test accuracy =  0.80124\n",
            "epoch =  20  train loss =  0.614382187187029  test loss =   0.7338585518500531  train accuracy =  0.614382187187029 test accuracy =  0.80081\n",
            "epoch =  20  train loss =  0.6422949957485375  test loss =   0.7335972555010729  train accuracy =  0.6422949957485375 test accuracy =  0.8001499999999999\n",
            "epoch =  30  train loss =  0.5905365247459919  test loss =   0.7348638463281181  train accuracy =  0.5905365247459919 test accuracy =  0.8004899999999999\n",
            "epoch =  30  train loss =  0.5936043247849743  test loss =   0.7348864308410429  train accuracy =  0.5936043247849743 test accuracy =  0.80033\n",
            "epoch =  30  train loss =  0.588987390112704  test loss =   0.7349337862777989  train accuracy =  0.588987390112704 test accuracy =  0.80277\n",
            "epoch =  30  train loss =  0.5981449359172004  test loss =   0.734765909073172  train accuracy =  0.5981449359172004 test accuracy =  0.80031\n",
            "epoch =  30  train loss =  0.594671370911479  test loss =   0.7353031126416222  train accuracy =  0.594671370911479 test accuracy =  0.80035\n",
            "epoch =  40  train loss =  0.5963533349418993  test loss =   0.735833629476224  train accuracy =  0.5963533349418993 test accuracy =  0.80087\n",
            "epoch =  40  train loss =  0.6103779310396426  test loss =   0.7361148283083282  train accuracy =  0.6103779310396426 test accuracy =  0.80185\n",
            "epoch =  40  train loss =  0.6093374216722943  test loss =   0.7362731614377223  train accuracy =  0.6093374216722943 test accuracy =  0.80008\n",
            "epoch =  40  train loss =  0.5843342191251552  test loss =   0.736166033851131  train accuracy =  0.5843342191251552 test accuracy =  0.8004\n",
            "epoch =  40  train loss =  0.6088600087486236  test loss =   0.7360714764929236  train accuracy =  0.6088600087486236 test accuracy =  0.8005599999999999\n",
            "epoch =  50  train loss =  0.6007588779684739  test loss =   0.7365230262052685  train accuracy =  0.6007588779684739 test accuracy =  0.80052\n",
            "epoch =  50  train loss =  0.6054074713043189  test loss =   0.7365758425222082  train accuracy =  0.6054074713043189 test accuracy =  0.80116\n",
            "epoch =  50  train loss =  0.6056400224370082  test loss =   0.7366239657544589  train accuracy =  0.6056400224370082 test accuracy =  0.80048\n",
            "epoch =  50  train loss =  0.5870932422459678  test loss =   0.7365896177760836  train accuracy =  0.5870932422459678 test accuracy =  0.80064\n",
            "epoch =  50  train loss =  0.604038762030271  test loss =   0.7367228376899894  train accuracy =  0.604038762030271 test accuracy =  0.80064\n",
            "epoch =  60  train loss =  0.5833128126159061  test loss =   0.7367878471615346  train accuracy =  0.5833128126159061 test accuracy =  0.80104\n",
            "epoch =  60  train loss =  0.5925385467535855  test loss =   0.7367992354094214  train accuracy =  0.5925385467535855 test accuracy =  0.80097\n",
            "epoch =  60  train loss =  0.5931375513826499  test loss =   0.7367982713822822  train accuracy =  0.5931375513826499 test accuracy =  0.8013\n",
            "epoch =  60  train loss =  0.602509709743411  test loss =   0.7368119140515701  train accuracy =  0.602509709743411 test accuracy =  0.80105\n",
            "epoch =  60  train loss =  0.5827479434815543  test loss =   0.7368143240394277  train accuracy =  0.5827479434815543 test accuracy =  0.80111\n",
            "epoch =  70  train loss =  0.5681212433993441  test loss =   0.7368803154792319  train accuracy =  0.5681212433993441 test accuracy =  0.8011699999999999\n",
            "epoch =  70  train loss =  0.5739543905183951  test loss =   0.7368731816594616  train accuracy =  0.5739543905183951 test accuracy =  0.8009999999999999\n",
            "epoch =  70  train loss =  0.5877684131824296  test loss =   0.73687374793488  train accuracy =  0.5877684131824296 test accuracy =  0.80101\n",
            "epoch =  70  train loss =  0.6042769134022873  test loss =   0.7368857171835905  train accuracy =  0.6042769134022873 test accuracy =  0.80125\n",
            "epoch =  70  train loss =  0.6014821050266581  test loss =   0.736887806942174  train accuracy =  0.6014821050266581 test accuracy =  0.80115\n",
            "epoch =  80  train loss =  0.5920574604549564  test loss =   0.7369101927757711  train accuracy =  0.5920574604549564 test accuracy =  0.80116\n",
            "epoch =  80  train loss =  0.5911366183214056  test loss =   0.7369115306209039  train accuracy =  0.5911366183214056 test accuracy =  0.80113\n",
            "epoch =  80  train loss =  0.5907165696930148  test loss =   0.7369126888175542  train accuracy =  0.5907165696930148 test accuracy =  0.8012\n",
            "epoch =  80  train loss =  0.6011889080426529  test loss =   0.7369182297254007  train accuracy =  0.6011889080426529 test accuracy =  0.80107\n",
            "epoch =  80  train loss =  0.5930667540825527  test loss =   0.7369169618756619  train accuracy =  0.5930667540825527 test accuracy =  0.80123\n",
            "epoch =  90  train loss =  0.5727367245828247  test loss =   0.7369215659935658  train accuracy =  0.5727367245828247 test accuracy =  0.80126\n",
            "epoch =  90  train loss =  0.5879116125070926  test loss =   0.7369201285378489  train accuracy =  0.5879116125070926 test accuracy =  0.8012\n",
            "epoch =  90  train loss =  0.5816875828421784  test loss =   0.7369200693805706  train accuracy =  0.5816875828421784 test accuracy =  0.80118\n",
            "epoch =  90  train loss =  0.5747001448154248  test loss =   0.7369177256839975  train accuracy =  0.5747001448154248 test accuracy =  0.80128\n",
            "epoch =  90  train loss =  0.5656303086721175  test loss =   0.7369199974434323  train accuracy =  0.5656303086721175 test accuracy =  0.80123\n",
            "epoch =  100  train loss =  0.6045803785398524  test loss =   0.7369259985594606  train accuracy =  0.6045803785398524 test accuracy =  0.8011699999999999\n",
            "epoch =  100  train loss =  0.5885161993685293  test loss =   0.7369266331602645  train accuracy =  0.5885161993685293 test accuracy =  0.80126\n",
            "epoch =  100  train loss =  0.610249469239837  test loss =   0.7369262572279119  train accuracy =  0.610249469239837 test accuracy =  0.8012\n",
            "epoch =  100  train loss =  0.5518027747816282  test loss =   0.7369260831222855  train accuracy =  0.5518027747816282 test accuracy =  0.80126\n",
            "epoch =  100  train loss =  0.5997168217086782  test loss =   0.7369260245065415  train accuracy =  0.5997168217086782 test accuracy =  0.80123\n",
            "epoch =  110  train loss =  0.6016207278632667  test loss =   0.7369275159395765  train accuracy =  0.6016207278632667 test accuracy =  0.8011699999999999\n",
            "epoch =  110  train loss =  0.5827994276245595  test loss =   0.736927453559755  train accuracy =  0.5827994276245595 test accuracy =  0.8011699999999999\n",
            "epoch =  110  train loss =  0.5994330447736703  test loss =   0.7369277816130889  train accuracy =  0.5994330447736703 test accuracy =  0.8011699999999999\n",
            "epoch =  110  train loss =  0.5517915355028208  test loss =   0.7369276621690319  train accuracy =  0.5517915355028208 test accuracy =  0.8011699999999999\n",
            "epoch =  110  train loss =  0.5763565323478862  test loss =   0.7369275886857697  train accuracy =  0.5763565323478862 test accuracy =  0.8011699999999999\n",
            "epoch =  120  train loss =  0.5842203660320877  test loss =   0.736928080921785  train accuracy =  0.5842203660320877 test accuracy =  0.8011699999999999\n",
            "epoch =  120  train loss =  0.6147700096253196  test loss =   0.7369280030016081  train accuracy =  0.6147700096253196 test accuracy =  0.8011699999999999\n",
            "epoch =  120  train loss =  0.5714990276699546  test loss =   0.7369279385784799  train accuracy =  0.5714990276699546 test accuracy =  0.8011699999999999\n",
            "epoch =  120  train loss =  0.5742134254152125  test loss =   0.7369278932864182  train accuracy =  0.5742134254152125 test accuracy =  0.8011699999999999\n",
            "epoch =  120  train loss =  0.5776573728860377  test loss =   0.7369279343179842  train accuracy =  0.5776573728860377 test accuracy =  0.8011699999999999\n",
            "epoch =  130  train loss =  0.5914064602669493  test loss =   0.7369282516660646  train accuracy =  0.5914064602669493 test accuracy =  0.8011699999999999\n",
            "epoch =  130  train loss =  0.5908616601682644  test loss =   0.7369282704367344  train accuracy =  0.5908616601682644 test accuracy =  0.8011699999999999\n",
            "epoch =  130  train loss =  0.5784595545433122  test loss =   0.7369282828858759  train accuracy =  0.5784595545433122 test accuracy =  0.8011699999999999\n",
            "epoch =  130  train loss =  0.5679958660987419  test loss =   0.7369282769248366  train accuracy =  0.5679958660987419 test accuracy =  0.8011699999999999\n",
            "epoch =  130  train loss =  0.5746485741543754  test loss =   0.7369282488249009  train accuracy =  0.5746485741543754 test accuracy =  0.8011699999999999\n",
            "epoch =  140  train loss =  0.5676321693440283  test loss =   0.7369283319220423  train accuracy =  0.5676321693440283 test accuracy =  0.8011699999999999\n",
            "epoch =  140  train loss =  0.5734132332008212  test loss =   0.7369283337932703  train accuracy =  0.5734132332008212 test accuracy =  0.8011699999999999\n",
            "epoch =  140  train loss =  0.5870150199438953  test loss =   0.7369283278044735  train accuracy =  0.5870150199438953 test accuracy =  0.8011699999999999\n",
            "epoch =  140  train loss =  0.5873645170891054  test loss =   0.7369283367264832  train accuracy =  0.5873645170891054 test accuracy =  0.8011699999999999\n",
            "epoch =  140  train loss =  0.5789830645268982  test loss =   0.7369283326427453  train accuracy =  0.5789830645268982 test accuracy =  0.8011699999999999\n",
            "epoch =  150  train loss =  0.601070979253955  test loss =   0.7369283606734542  train accuracy =  0.601070979253955 test accuracy =  0.8011699999999999\n",
            "epoch =  150  train loss =  0.5919679428945883  test loss =   0.7369283587988635  train accuracy =  0.5919679428945883 test accuracy =  0.8011699999999999\n",
            "epoch =  150  train loss =  0.5842189555011356  test loss =   0.7369283588483716  train accuracy =  0.5842189555011356 test accuracy =  0.8011699999999999\n",
            "epoch =  150  train loss =  0.5884983838518709  test loss =   0.7369283607377195  train accuracy =  0.5884983838518709 test accuracy =  0.8011699999999999\n",
            "epoch =  150  train loss =  0.572706124774468  test loss =   0.7369283589456198  train accuracy =  0.572706124774468 test accuracy =  0.8011699999999999\n",
            "epoch =  160  train loss =  0.6102345882376425  test loss =   0.7369283713727363  train accuracy =  0.6102345882376425 test accuracy =  0.8011699999999999\n",
            "epoch =  160  train loss =  0.5752125283307047  test loss =   0.7369283720333138  train accuracy =  0.5752125283307047 test accuracy =  0.8011699999999999\n",
            "epoch =  160  train loss =  0.5774828784807546  test loss =   0.7369283720376893  train accuracy =  0.5774828784807546 test accuracy =  0.8011699999999999\n",
            "epoch =  160  train loss =  0.6025710629617127  test loss =   0.7369283732055003  train accuracy =  0.6025710629617127 test accuracy =  0.8011699999999999\n",
            "epoch =  160  train loss =  0.5934110704401854  test loss =   0.7369283728635577  train accuracy =  0.5934110704401854 test accuracy =  0.8011699999999999\n",
            "epoch =  170  train loss =  0.5749378250477856  test loss =   0.7369283751890934  train accuracy =  0.5749378250477856 test accuracy =  0.8011699999999999\n",
            "epoch =  170  train loss =  0.5868954442103049  test loss =   0.736928375711923  train accuracy =  0.5868954442103049 test accuracy =  0.8011699999999999\n",
            "epoch =  170  train loss =  0.5707716032548018  test loss =   0.7369283751877941  train accuracy =  0.5707716032548018 test accuracy =  0.8011699999999999\n",
            "epoch =  170  train loss =  0.5842188598097628  test loss =   0.7369283756779055  train accuracy =  0.5842188598097628 test accuracy =  0.8011699999999999\n",
            "epoch =  170  train loss =  0.6045693320550729  test loss =   0.7369283755358359  train accuracy =  0.6045693320550729 test accuracy =  0.8011699999999999\n",
            "epoch =  180  train loss =  0.5981985834074326  test loss =   0.7369283766385933  train accuracy =  0.5981985834074326 test accuracy =  0.8011699999999999\n",
            "epoch =  180  train loss =  0.6039552707274777  test loss =   0.7369283761792879  train accuracy =  0.6039552707274777 test accuracy =  0.8011699999999999\n",
            "epoch =  180  train loss =  0.6045693163521998  test loss =   0.7369283764248037  train accuracy =  0.6045693163521998 test accuracy =  0.8011699999999999\n",
            "epoch =  180  train loss =  0.5891006976335905  test loss =   0.7369283762726834  train accuracy =  0.5891006976335905 test accuracy =  0.8011699999999999\n",
            "epoch =  180  train loss =  0.5838943438592953  test loss =   0.7369283763594858  train accuracy =  0.5838943438592953 test accuracy =  0.8011699999999999\n",
            "epoch =  190  train loss =  0.5802314313981416  test loss =   0.7369283771294237  train accuracy =  0.5802314313981416 test accuracy =  0.8011699999999999\n",
            "epoch =  190  train loss =  0.5983874627244558  test loss =   0.7369283772253022  train accuracy =  0.5983874627244558 test accuracy =  0.8011699999999999\n",
            "epoch =  190  train loss =  0.5838943390352425  test loss =   0.7369283773044836  train accuracy =  0.5838943390352425 test accuracy =  0.8011699999999999\n",
            "epoch =  190  train loss =  0.5823229072288987  test loss =   0.7369283773460474  train accuracy =  0.5823229072288987 test accuracy =  0.8011699999999999\n",
            "epoch =  190  train loss =  0.5881641108097837  test loss =   0.7369283771964761  train accuracy =  0.5881641108097837 test accuracy =  0.8011699999999999\n",
            "epoch =  200  train loss =  0.5752124927199812  test loss =   0.7369283773444636  train accuracy =  0.5752124927199812 test accuracy =  0.8011699999999999\n",
            "epoch =  200  train loss =  0.5905483539940911  test loss =   0.7369283773226128  train accuracy =  0.5905483539940911 test accuracy =  0.8011699999999999\n",
            "epoch =  200  train loss =  0.5977190334065556  test loss =   0.7369283773094002  train accuracy =  0.5977190334065556 test accuracy =  0.8011699999999999\n",
            "epoch =  200  train loss =  0.5919678416239397  test loss =   0.7369283773210312  train accuracy =  0.5919678416239397 test accuracy =  0.8011699999999999\n",
            "epoch =  200  train loss =  0.6136502392641545  test loss =   0.7369283773385229  train accuracy =  0.6136502392641545 test accuracy =  0.8011699999999999\n",
            "epoch =  210  train loss =  0.5780937803321587  test loss =   0.7369283774166389  train accuracy =  0.5780937803321587 test accuracy =  0.8011699999999999\n",
            "epoch =  210  train loss =  0.6029485791981615  test loss =   0.7369283774126254  train accuracy =  0.6029485791981615 test accuracy =  0.8011699999999999\n",
            "epoch =  210  train loss =  0.5844732388111994  test loss =   0.7369283774046117  train accuracy =  0.5844732388111994 test accuracy =  0.8011699999999999\n",
            "epoch =  210  train loss =  0.5904098419081493  test loss =   0.7369283774128862  train accuracy =  0.5904098419081493 test accuracy =  0.8011699999999999\n",
            "epoch =  210  train loss =  0.5737844109207655  test loss =   0.7369283774224847  train accuracy =  0.5737844109207655 test accuracy =  0.8011699999999999\n",
            "epoch =  220  train loss =  0.5742155808970251  test loss =   0.7369283774416107  train accuracy =  0.5742155808970251 test accuracy =  0.8011699999999999\n",
            "epoch =  220  train loss =  0.5885372834775473  test loss =   0.7369283774465661  train accuracy =  0.5885372834775473 test accuracy =  0.8011699999999999\n",
            "epoch =  220  train loss =  0.5939197990823274  test loss =   0.7369283774412404  train accuracy =  0.5939197990823274 test accuracy =  0.8011699999999999\n",
            "epoch =  220  train loss =  0.5709060990120678  test loss =   0.7369283774420543  train accuracy =  0.5709060990120678 test accuracy =  0.8011699999999999\n",
            "epoch =  220  train loss =  0.6013541986003831  test loss =   0.7369283774398165  train accuracy =  0.6013541986003831 test accuracy =  0.8011699999999999\n",
            "epoch =  230  train loss =  0.5810229412886693  test loss =   0.7369283774523274  train accuracy =  0.5810229412886693 test accuracy =  0.8011699999999999\n",
            "epoch =  230  train loss =  0.5922752320236194  test loss =   0.7369283774512914  train accuracy =  0.5922752320236194 test accuracy =  0.8011699999999999\n",
            "epoch =  230  train loss =  0.5934110139622881  test loss =   0.7369283774529357  train accuracy =  0.5934110139622881 test accuracy =  0.8011699999999999\n",
            "epoch =  230  train loss =  0.5905483535051328  test loss =   0.73692837745088  train accuracy =  0.5905483535051328 test accuracy =  0.8011699999999999\n",
            "epoch =  230  train loss =  0.5868954328227607  test loss =   0.7369283774509917  train accuracy =  0.5868954328227607 test accuracy =  0.8011699999999999\n",
            "epoch =  240  train loss =  0.5750217920166945  test loss =   0.7369283774556366  train accuracy =  0.5750217920166945 test accuracy =  0.8011699999999999\n",
            "epoch =  240  train loss =  0.5885372833883716  test loss =   0.7369283774559928  train accuracy =  0.5885372833883716 test accuracy =  0.8011699999999999\n",
            "epoch =  240  train loss =  0.5742155808541335  test loss =   0.736928377455947  train accuracy =  0.5742155808541335 test accuracy =  0.8011699999999999\n",
            "epoch =  240  train loss =  0.5742590552850563  test loss =   0.7369283774557678  train accuracy =  0.5742590552850563 test accuracy =  0.8011699999999999\n",
            "epoch =  240  train loss =  0.5678901626644041  test loss =   0.7369283774557304  train accuracy =  0.5678901626644041 test accuracy =  0.8011699999999999\n",
            "epoch =  250  train loss =  0.5816486307711556  test loss =   0.736928377456962  train accuracy =  0.5816486307711556 test accuracy =  0.8011699999999999\n",
            "epoch =  250  train loss =  0.58689543278583  test loss =   0.7369283774569103  train accuracy =  0.58689543278583 test accuracy =  0.8011699999999999\n",
            "epoch =  250  train loss =  0.5774828509124094  test loss =   0.736928377456937  train accuracy =  0.5774828509124094 test accuracy =  0.8011699999999999\n",
            "epoch =  250  train loss =  0.584493393733477  test loss =   0.7369283774570383  train accuracy =  0.584493393733477 test accuracy =  0.8011699999999999\n",
            "epoch =  250  train loss =  0.5746475471873445  test loss =   0.7369283774571328  train accuracy =  0.5746475471873445 test accuracy =  0.8011699999999999\n",
            "epoch =  260  train loss =  0.5774828509081503  test loss =   0.7369283774574509  train accuracy =  0.5774828509081503 test accuracy =  0.8011699999999999\n",
            "epoch =  260  train loss =  0.5780937801420931  test loss =   0.7369283774574452  train accuracy =  0.5780937801420931 test accuracy =  0.8011699999999999\n",
            "epoch =  260  train loss =  0.574937815591401  test loss =   0.736928377457402  train accuracy =  0.574937815591401 test accuracy =  0.8011699999999999\n",
            "epoch =  260  train loss =  0.6106275171422958  test loss =   0.7369283774574672  train accuracy =  0.6106275171422958 test accuracy =  0.8011699999999999\n",
            "epoch =  260  train loss =  0.5878709446822626  test loss =   0.7369283774574669  train accuracy =  0.5878709446822626 test accuracy =  0.8011699999999999\n",
            "epoch =  270  train loss =  0.5884982577149827  test loss =   0.736928377457623  train accuracy =  0.5884982577149827 test accuracy =  0.8011699999999999\n",
            "epoch =  270  train loss =  0.5714968090695511  test loss =   0.7369283774575929  train accuracy =  0.5714968090695511 test accuracy =  0.8011699999999999\n",
            "epoch =  270  train loss =  0.6102345643056984  test loss =   0.736928377457614  train accuracy =  0.6102345643056984 test accuracy =  0.8011699999999999\n",
            "epoch =  270  train loss =  0.5859010788893554  test loss =   0.7369283774576197  train accuracy =  0.5859010788893554 test accuracy =  0.8011699999999999\n",
            "epoch =  270  train loss =  0.5943191158070774  test loss =   0.7369283774576295  train accuracy =  0.5943191158070774 test accuracy =  0.8011699999999999\n",
            "epoch =  280  train loss =  0.5838943372763078  test loss =   0.7369283774576847  train accuracy =  0.5838943372763078 test accuracy =  0.8011699999999999\n",
            "epoch =  280  train loss =  0.5934110139130396  test loss =   0.7369283774576783  train accuracy =  0.5934110139130396 test accuracy =  0.8011699999999999\n",
            "epoch =  280  train loss =  0.5908609380094046  test loss =   0.7369283774576761  train accuracy =  0.5908609380094046 test accuracy =  0.8011699999999999\n",
            "epoch =  280  train loss =  0.5707715895168635  test loss =   0.7369283774576855  train accuracy =  0.5707715895168635 test accuracy =  0.8011699999999999\n",
            "epoch =  280  train loss =  0.5774828509071719  test loss =   0.7369283774576874  train accuracy =  0.5774828509071719 test accuracy =  0.8011699999999999\n",
            "epoch =  290  train loss =  0.5929247501463811  test loss =   0.7369283774577096  train accuracy =  0.5929247501463811 test accuracy =  0.8011699999999999\n",
            "epoch =  290  train loss =  0.5842188438018118  test loss =   0.7369283774577127  train accuracy =  0.5842188438018118 test accuracy =  0.8011699999999999\n",
            "epoch =  290  train loss =  0.5922752319952114  test loss =   0.7369283774577141  train accuracy =  0.5922752319952114 test accuracy =  0.8011699999999999\n",
            "epoch =  290  train loss =  0.5678901626523364  test loss =   0.7369283774577158  train accuracy =  0.5678901626523364 test accuracy =  0.8011699999999999\n",
            "epoch =  290  train loss =  0.5908809806865899  test loss =   0.7369283774577132  train accuracy =  0.5908809806865899 test accuracy =  0.8011699999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQh3r5HYIggn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "iN2otSwBqnym",
        "outputId": "a4e5af62-10a8-4b5d-972a-a25de0f248e0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(training_loss_history)\n",
        "f, axarr = plt.subplots(1, 10)\n",
        "f.set_size_inches(16, 6)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}